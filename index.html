<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="description" content="MoDiT: A novel framework combining 3DMM with a Diffusion-based Transformer for audio-driven talking head generation.">
  <meta name="keywords" content="MoDiT, Talking Head Generation, Diffusion Transformer, 3DMM">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>MoDiT: Learning Highly Consistent 3D Motion Coefficients</title>

  <link href="https://fonts.googleapis.com/css2?family=Google+Sans:wght@400;700&display=swap" rel="stylesheet">
  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css">
  <style>
    body {
      font-family: 'Google Sans', sans-serif;
    }
    .hero {
      background: #ffffff; /* Plain white background */
      color: #000000; /* Black text color */
    }
    .hero .title {
      font-size: 2.5rem;
    }
    .hero .publication-links a {
      margin: 0.5rem;
    }
    .teaser img {
      border-radius: 8px;
      box-shadow: 0 4px 8px rgba(0, 0, 0, 0.2);
    }
    .section img {
      border-radius: 8px;
      box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);
    }
    .section p, .section ul, .section ol {
      line-height: 1.8;
    }
    footer {
      background: #f7f7f7; /* Light gray background */
      color: #333333; /* Dark gray text */
      padding: 1.5rem 0;
    }
    footer a {
      color: #333333;
      text-decoration: underline;
    }
    footer a:hover {
      color: #00d1b2;
    }
  </style>
</head>
<body>
  <!-- Navbar -->
<nav class="navbar is-transparent">
  <div class="navbar-brand">
    <a class="navbar-item" href="#">
      <strong>MoDiT</strong>
    </a>
  </div>
</nav>

<!-- Hero Section -->
<section class="hero is-fullheight-with-navbar">
  <div class="hero-body">
    <div class="container has-text-centered">
      <h1 class="title is-1">MoDiT: Learning Highly Consistent 3D Motion Coefficients</h1>
      <h2 class="subtitle is-4">Yucheng Wang<sup>1</sup> and Dan Xu<sup>1</sup></h2>
      <p class="is-size-5">The Hong Kong University of Science and Technology</p>
      <div class="publication-links">
        <a href="https://arxiv.org/abs/xxxx.xxxxx" class="button is-rounded is-light">
          <span class="icon"><i class="fas fa-file-alt"></i></span>
          <span>arXiv</span>
        </a>
        <a href="https://github.com/dummy/modit" class="button is-rounded is-light">
          <span class="icon"><i class="fab fa-github"></i></span>
          <span>Code</span>
        </a>
        <a href="./static/videos/modit_demo.mp4" class="button is-rounded is-light">
          <span class="icon"><i class="fab fa-youtube"></i></span>
          <span>Video</span>
        </a>
      </div>
    </div>
  </div>
</section>

<!-- Teaser Section -->
<section class="section teaser">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-half has-text-centered">
        <img src="./static/images/Teaser.png" alt="Teaser Image" style="width: 100%;">
        <h2 class="subtitle is-4 mt-4">MoDiT combines 3DMM with a Diffusion-based Transformer to generate realistic talking head animations from audio with a single image.</h2>
      </div>
    </div>
  </div>
</section>

<!-- Abstract Section -->
<section class="section">
  <div class="container">
    <h2 class="title is-3 has-text-centered">Abstract</h2>
    <div class="columns is-centered">
      <div class="column is-three-quarters">
        <p>Audio-driven talking head generation is critical for applications such as virtual assistants, video games, and films, where natural lip movements are essential. Despite progress in this field, challenges remain in producing both consistent and realistic facial animations. Existing methods often face three major limitations:</p>
        <ol>
          <li>Temporal jittering caused by weak temporal constraints, resulting in frame inconsistencies.</li>
          <li>Identity drift due to insufficient 3D information extraction, leading to poor preservation of facial identity.</li>
          <li>Unnatural blinking behavior due to inadequate modeling of realistic blink dynamics.</li>
        </ol>
        <p>To address these issues, we propose MoDiT, a novel framework that combines the 3D Morphable Model (3DMM) with a Diffusion-based Transformer. Our contributions include:</p>
        <ol>
          <li>A hierarchical denoising strategy with revised temporal attention and biased self/cross-attention mechanisms.</li>
          <li>The integration of 3DMM coefficients to ensure accurate 3D-informed optical flow prediction.</li>
          <li>A refined blinking strategy to model natural eye movements.</li>
        </ol>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <h2 class="title is-3">Overview of the Diffusion Transformer Pipeline</h2>
    <div class="columns is-centered is-multiline">
      <div class="column is-four-fifths has-text-centered">
        <img src="./static/images/Pipeline.png" alt="Pipeline Image" style="width: 100%; height: auto;">
      </div>
      <div class="column is-four-fifths has-text-centered">
        <p class="subtitle is-5">
          Overview of the Diffusion Transformer Pipeline, showcasing the denoising stages with temporal and spatial condition injection. The integration of 3DMM coefficients to provide explicit spatial constraints, ensuring accurate 3D-informed optical flow prediction and improved lip synchronization. We also employ a hierarchical denoising strategy with revised temporal attention and biased self/cross-attention mechanisms, enabling the model to refine lip synchronization and progressively enhance full-face coherence, effectively mitigating temporal jittering.
        </p>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <h2 class="title is-3">Comparison</h2>
    <div class="columns is-centered is-multiline">
      <!-- Images now stack on top of one another -->
      <div class="column is-four-fifths has-text-centered">
        <img src="./static/images/Compare.png" alt="Table 1 Image" style="width: 100%; height: auto;">
      </div>
      <div class="column is-four-fifths has-text-centered">
        <img src="./static/images/Table.png" alt="Table 2 Image" style="width: 100%; height: auto;">
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-four-fifths has-text-centered">
        <h2 class="title is-3">Demo Video</h2>
        <video controls autoplay muted loop playsinline style="width: 100%; height: auto;">
          <source src="./static/videos/Video Demo.mp4" type="video/mp4">
        </video>
      </div>
    </div>
  </div>
</section>


<!-- Footer -->
<footer class="footer">
  <div class="content has-text-centered">
    <p>Â© 2025 MoDiT. Licensed under <a href="http://creativecommons.org/licenses/by-sa/4.0/">CC BY-SA 4.0</a>.</p>
    <p>Source code for this website is based on the <a href="https://nerfies.github.io/">Nerfies</a> project.</p>
  </div>
</footer>

</body>
</html>